{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 1275\n",
    "WINDOW_STEP = 21\n",
    "output_name= \"feature_120_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fdaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, iqr\n",
    "from scipy.fft import fft\n",
    "from scipy.stats import entropy\n",
    "import pywt\n",
    "\n",
    "# ======================== Frequency-domain features ======================== #\n",
    "def get_fft_stats(df, columns=['steering', 'throttle', 'brake']):\n",
    "    \"\"\"\n",
    "    Compute FFT-based frequency-domain features for selected signals.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        signal = df[col].dropna().values  # Remove NaN values\n",
    "\n",
    "        if len(signal) < 2:\n",
    "            continue  # Ignore too-short signals\n",
    "\n",
    "        # 1. Perform FFT and keep only positive frequency components\n",
    "        fft_vals = np.abs(fft(signal))\n",
    "        fft_vals = fft_vals[:len(fft_vals)//2]\n",
    "\n",
    "        # 2. Spectral statistics\n",
    "        features[f'FFT_{col}_mean'] = np.mean(fft_vals)\n",
    "        features[f'FFT_{col}_std'] = np.std(fft_vals)\n",
    "        features[f'FFT_{col}_max'] = np.max(fft_vals)\n",
    "        features[f'FFT_{col}_min'] = np.min(fft_vals)\n",
    "        features[f'FFT_{col}_energy'] = np.sum(fft_vals ** 2)\n",
    "\n",
    "        # 3. Spectral entropy\n",
    "        psd = fft_vals ** 2\n",
    "        psd_norm = psd / np.sum(psd) if np.sum(psd) != 0 else psd\n",
    "        features[f'FFT_{col}_entropy'] = entropy(psd_norm)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# ======================== Wavelet transform features ======================= #\n",
    "def extract_wavelet_features(df, columns=['steering', 'throttle', 'brake'], wavelet='db4', level=3):\n",
    "    \"\"\"\n",
    "    Extract wavelet-based signal energy, mean, entropy for each decomposition level.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        signal = df[col].dropna().values\n",
    "        if len(signal) < 2:\n",
    "            continue\n",
    "\n",
    "        coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "\n",
    "        for i, coeff in enumerate(coeffs):\n",
    "            prefix = f'{col}_L{i}'\n",
    "            features[f'WVL_{prefix}_mean'] = np.mean(coeff)\n",
    "            features[f'WVL_{prefix}_std'] = np.std(coeff)\n",
    "            features[f'WVL_{prefix}_max'] = np.max(coeff)\n",
    "            features[f'WVL_{prefix}_energy'] = np.sum(np.square(coeff))\n",
    "            coeff_norm = np.square(coeff) / np.sum(np.square(coeff)) if np.sum(np.square(coeff)) > 0 else coeff\n",
    "            features[f'WVL_{prefix}_entropy'] = entropy(coeff_norm)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# ======================== Handcrafted pedal features ====================== #\n",
    "def extract_pedal(pedal_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Extract handcrafted driving maneuver features from pedal signals.\n",
    "    \"\"\"\n",
    "    res = {\n",
    "        \"LAST_steer_sum\": np.nan,\n",
    "        \"LAST_steer_abs_sum\": np.nan,\n",
    "        \"LAST_steer_flucuate_times\": np.nan,\n",
    "        \"LAST_steer_sum_per_fulct\": np.nan,\n",
    "        \"LAST_steer_max_fluct\": np.nan,\n",
    "        \"LAST_steer_mean_fluct_speed\": np.nan,\n",
    "        \"LAST_steer_max_fluct_speed\": np.nan,\n",
    "        \"LAST_throttle_duration\": np.nan,\n",
    "        \"LAST_brake_duration\": np.nan,\n",
    "        \"LAST_throttle_brake_ratio\": np.nan,\n",
    "        \"LAST_brake_times\": np.nan,\n",
    "        \"LAST_throttle_auc\": np.nan,\n",
    "    }\n",
    "\n",
    "    if pedal_df.shape[0] == 0:\n",
    "        return res\n",
    "    \n",
    "    pedal_df = pedal_df.copy()\n",
    "    pedal_df[\"throttle\"] = -pedal_df[\"throttle\"] + 32767.0\n",
    "    pedal_df[\"brake\"] = -pedal_df[\"brake\"] + 32767.0\n",
    "\n",
    "    res[\"LAST_steer_sum\"] = pedal_df[\"steering\"].sum()\n",
    "    res[\"LAST_steer_abs_sum\"] = np.abs(pedal_df[\"steering\"]).sum()\n",
    "\n",
    "    try:\n",
    "        pedal_df[\"LAST_pass_zero\"] = (pedal_df[\"steering\"] * pedal_df[\"steering\"].shift(1)).map(lambda x: 1 if x <= 0 else 0)\n",
    "        res[\"LAST_steer_flucuate_times\"] = pedal_df[\"LAST_pass_zero\"].sum()\n",
    "        res[\"LAST_steer_sum_per_fulct\"] = 0 if res[\"LAST_steer_flucuate_times\"] == 0 else res[\"LAST_steer_abs_sum\"] / res[\"LAST_flucuate_times\"]\n",
    "    except:\n",
    "        res[\"LAST_flucuate_times\"] = 0\n",
    "        res[\"LAST_steer_sum_per_fulct\"] = 0\n",
    "\n",
    "    res[\"LAST_steer_max_fluct\"] = np.abs(pedal_df[\"steering\"]).max()\n",
    "    res[\"LAST_steer_mean_fluct_speed\"] = np.nanmean(np.abs(pedal_df[\"steering_derivative\"]))\n",
    "    res[\"LAST_steer_max_fluct_speed\"] = np.abs(pedal_df[\"steering_derivative\"]).max()\n",
    "    \n",
    "    pedal_df[\"dura\"] = pedal_df[\"timestamp\"].shift(-1) - pedal_df[\"timestamp\"]\n",
    "    res[\"LAST_throttle_duration\"] = pedal_df[~(pedal_df[\"throttle\"] == 0)][\"dura\"].sum()\n",
    "    res[\"LAST_brake_duration\"] = pedal_df[~(pedal_df[\"brake\"] == 0)][\"dura\"].sum()\n",
    "    res[\"LAST_throttle_brake_ratio\"] = res[\"LAST_throttle_duration\"] / (res[\"LAST_brake_duration\"] + 0.01)\n",
    "\n",
    "    _temp_times = 0\n",
    "    _last_idx = pedal_df.index[0]\n",
    "    for idx, row in pedal_df[pedal_df[\"brake\"] == 0].iterrows():\n",
    "        if not (idx - _last_idx == 1 or idx - _last_idx == 0):\n",
    "            _temp_times += 1\n",
    "        _last_idx = idx\n",
    "    res[\"LAST_brake_times\"] = _temp_times\n",
    "    res[\"LAST_throttle_auc\"] = pedal_df[\"throttle\"].sum()\n",
    "    return res\n",
    "\n",
    "\n",
    "# ======================== New pedal features ============================== #\n",
    "def extract_new_pedal_feature(pedal_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    New pedal dynamics and spectral feature extraction.\n",
    "    \"\"\"\n",
    "    res = {\n",
    "        \"NewPedal_steering_Change_quantile_mean\": np.nan,\n",
    "        \"NewPedal_steering_fft_Kurtosis\": np.nan,\n",
    "        \"NewPedal_steering_unique_value_ratio\": np.nan,\n",
    "        \"NewPedal_steering_FFT_Aggregated_Centroid\": np.nan\n",
    "    }\n",
    "\n",
    "    if pedal_df.shape[0] == 0:\n",
    "        return res\n",
    "\n",
    "    # Steering absolute change rate mean\n",
    "    steering_diff = pedal_df[\"steering\"].diff()\n",
    "    abs_change = steering_diff.abs()\n",
    "    time_diff = pedal_df[\"timestamp\"].diff().replace(0, np.nan)\n",
    "    steering_rate = abs_change / time_diff\n",
    "    res[\"NewPedal_steering_Change_quantile_mean\"] = steering_rate.mean()\n",
    "\n",
    "    # Spectral kurtosis\n",
    "    steering_signal = pedal_df[\"steering\"].dropna().values\n",
    "    fft_magnitude = np.abs(fft(steering_signal))\n",
    "    res[\"NewPedal_steering_fft_Kurtosis\"] = kurtosis(fft_magnitude, fisher=False)\n",
    "\n",
    "    # Unique value ratio\n",
    "    res[\"NewPedal_steering_unique_value_ratio\"] = pedal_df[\"steering\"].nunique() / len(pedal_df[\"steering\"])\n",
    "\n",
    "    # FFT centroid frequency\n",
    "    n = len(steering_signal)\n",
    "    fft_vals = fft(steering_signal)\n",
    "    fft_mag = np.abs(fft_vals)[:n//2]\n",
    "    freqs = np.fft.fftfreq(n, d=1.0/21.75)[:n//2]\n",
    "    res[\"NewPedal_steering_FFT_Aggregated_Centroid\"] = (\n",
    "        np.sum(freqs * fft_mag) / np.sum(fft_mag) if np.sum(fft_mag) > 0 else 0\n",
    "    )\n",
    "    return res\n",
    "\n",
    "\n",
    "# ======================== New speed features ============================== #\n",
    "def extract_new_speed_feature(speed_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    New features describing high-speed events, nonlinearity, and acceleration variability.\n",
    "    \"\"\"\n",
    "    res = {\n",
    "        \"NewSpeed_90%_quantile\": np.nan,\n",
    "        \"NewSpeed_C3\": np.nan,\n",
    "        \"NewSpeed_change_quantile_variance\": np.nan\n",
    "    }\n",
    "    if speed_df.shape[0] == 0:\n",
    "        return res\n",
    "\n",
    "    speed_series = speed_df[\"speed\"]\n",
    "    n = len(speed_series)\n",
    "\n",
    "    q90 = speed_series.quantile(0.9)\n",
    "    res[\"NewSpeed_90%_quantile\"] = len(speed_series[speed_series > q90]) / n\n",
    "\n",
    "    speed_values = speed_series.dropna().values\n",
    "    n = len(speed_values)\n",
    "    mu = np.mean(speed_values)\n",
    "\n",
    "    sum_c3 = sum(speed_values[i] * speed_values[i-1] * speed_values[i-2]\n",
    "                 for i in range(2, n))\n",
    "    res[\"NewSpeed_C3\"] = (sum_c3 / (n - 2)) - mu**3\n",
    "\n",
    "    abs_diff = np.abs(speed_series.diff().dropna())\n",
    "    res[\"NewSpeed_change_quantile_variance\"] = np.var(abs_diff)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# ======================== Eye-gaze geometry =============================== #\n",
    "from shapely.geometry import Point, box\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def compute_gaze_area(data: pd.DataFrame, radius=25):\n",
    "    \"\"\"\n",
    "    Compute union area of gaze points buffered to circles clipped inside screen.\n",
    "    \"\"\"\n",
    "    def create_circle(x, y, radius):\n",
    "        screen_box = box(0, 0, 1920, 1080)\n",
    "        circle = Point(x, y).buffer(radius)\n",
    "        return circle.intersection(screen_box)\n",
    "\n",
    "    data['circle'] = data.apply(lambda row: create_circle(row['Gaze point X'], row['Gaze point Y'], radius), axis=1)\n",
    "    union_area = unary_union(data['circle'].tolist())\n",
    "    return union_area.area\n",
    "\n",
    "\n",
    "# ======================== Eye movement segmentation features ============== #\n",
    "def extract_eye_movement_type(eye_df):\n",
    "    \"\"\"\n",
    "    Extract fixation/saccade counts and related amplitude/velocity statistics.\n",
    "    \"\"\"\n",
    "    eye_df = eye_df.copy()\n",
    "    res = {\n",
    "        \"GE_saccade_times\": np.nan,\n",
    "        \"GE_fixation_times\": np.nan,\n",
    "        \"GE_saccade_duration_mean\": np.nan,\n",
    "        \"GE_saccade_duration_std\": np.nan,\n",
    "        \"GE_saccade_duration_005quantiles\": np.nan,\n",
    "        \"GE_saccade_duration_095quantiles\": np.nan,\n",
    "        \"GE_saccade_duration_skewness\": np.nan,\n",
    "        \"GE_saccade_duration_kurtosis\": np.nan,\n",
    "        \"GE_fixation_duration_mean\": np.nan,\n",
    "        \"GE_fixation_duration_std\": np.nan,\n",
    "        \"GE_fixation_duration_005quantiles\": np.nan,\n",
    "        \"GE_fixation_duration_095quantiles\": np.nan,\n",
    "        \"GE_fixation_duration_skewness\": np.nan,\n",
    "        \"GE_fixation_duration_kurtosis\": np.nan,\n",
    "        \"GE_saccade_amplitude_mean\": np.nan,\n",
    "        \"GE_saccade_amplitude_std\": np.nan,\n",
    "        \"GE_saccade_amplitude_005quantiles\": np.nan,\n",
    "        \"GE_saccade_amplitude_095quantiles\": np.nan,\n",
    "        \"GE_saccade_amplitude_skewness\": np.nan,\n",
    "        \"GE_saccade_amplitude_kurtosis\": np.nan,\n",
    "        \"GE_saccade_peak_v_mean\": np.nan,\n",
    "        \"GE_saccade_peak_v_std\": np.nan,\n",
    "        \"GE_saccade_peak_v_005quantiles\": np.nan,\n",
    "        \"GE_saccade_peak_v_095quantiles\": np.nan,\n",
    "        \"GE_saccade_peak_v_skewness\": np.nan,\n",
    "        \"GE_saccade_peak_v_kurtosis\": np.nan,\n",
    "        \"GE_saccade_mean_v_mean\": np.nan,\n",
    "        \"GE_saccade_mean_v_std\": np.nan,\n",
    "        \"GE_saccade_mean_v_005quantiles\": np.nan,\n",
    "        \"GE_saccade_mean_v_095quantiles\": np.nan,\n",
    "        \"GE_saccade_mean_v_skewness\": np.nan,\n",
    "        \"GE_saccade_mean_v_kurtosis\": np.nan,\n",
    "    }\n",
    "\n",
    "    eye_df['dt'] = eye_df['timestamp'].diff()\n",
    "    eye_df['dx'] = eye_df['Gaze point X'].diff()\n",
    "    eye_df['dy'] = eye_df['Gaze point Y'].diff()\n",
    "    eye_df['velocity'] = np.sqrt(eye_df['dx']**2 + eye_df['dy']**2) / eye_df['dt']\n",
    "\n",
    "    eye_df['segment_id'] = (eye_df['Eye movement type'] != eye_df['Eye movement type'].shift()).cumsum()\n",
    "\n",
    "    results = []\n",
    "    for seg_id, group in eye_df.groupby('segment_id'):\n",
    "        seg_type = group['Eye movement type'].iloc[0]\n",
    "        start_time = group['timestamp'].iloc[0]\n",
    "        end_time = group['timestamp'].iloc[-1]\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        if seg_type == 'Fixation':\n",
    "            results.append({'type': 'Fixation', 'duration': duration})\n",
    "        elif seg_type == 'Saccade':\n",
    "            amplitude = np.sqrt((group['Gaze point X'].iloc[-1] - group['Gaze point X'].iloc[0])**2 +\n",
    "                                (group['Gaze point Y'].iloc[-1] - group['Gaze point Y'].iloc[0])**2)\n",
    "            results.append({\n",
    "                'type': 'Saccade',\n",
    "                'duration': duration,\n",
    "                'amplitude': amplitude,\n",
    "                'peak_velocity': group['velocity'].max(),\n",
    "                'mean_velocity': group['velocity'].mean()\n",
    "            })\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    if res_df.empty:\n",
    "        return res\n",
    "\n",
    "    fix_df = res_df[res_df['type'] == 'Fixation']\n",
    "    sac_df = res_df[res_df['type'] == 'Saccade']\n",
    "\n",
    "    res[\"GE_fixation_times\"] = len(fix_df)\n",
    "    res[\"GE_saccade_times\"] = len(sac_df)\n",
    "\n",
    "    if not fix_df.empty:\n",
    "        dur = fix_df['duration']\n",
    "        res[\"GE_fixation_duration_mean\"] = dur.mean()\n",
    "        res[\"GE_fixation_duration_std\"] = dur.std()\n",
    "        res[\"GE_fixation_duration_005quantiles\"] = dur.quantile(0.05)\n",
    "        res[\"GE_fixation_duration_095quantiles\"] = dur.quantile(0.95)\n",
    "        res[\"GE_fixation_duration_skewness\"] = skew(dur, nan_policy='omit')\n",
    "        res[\"GE_fixation_duration_kurtosis\"] = kurtosis(dur, nan_policy='omit')\n",
    "\n",
    "    if not sac_df.empty:\n",
    "        dur = sac_df['duration']\n",
    "        amp = sac_df['amplitude']\n",
    "        pv = sac_df['peak_velocity']\n",
    "        mv = sac_df['mean_velocity']\n",
    "\n",
    "        res[\"GE_saccade_duration_mean\"] = dur.mean()\n",
    "        res[\"GE_saccade_duration_std\"] = dur.std()\n",
    "        res[\"GE_saccade_duration_005quantiles\"] = dur.quantile(0.05)\n",
    "        res[\"GE_saccade_duration_095quantiles\"] = dur.quantile(0.95)\n",
    "        res[\"GE_saccade_duration_skewness\"] = skew(dur, nan_policy='omit')\n",
    "        res[\"GE_saccade_duration_kurtosis\"] = kurtosis(dur, nan_policy='omit')\n",
    "\n",
    "        res[\"GE_saccade_amplitude_mean\"] = amp.mean()\n",
    "        res[\"GE_saccade_amplitude_std\"] = amp.std()\n",
    "        res[\"GE_saccade_amplitude_005quantiles\"] = amp.quantile(0.05)\n",
    "        res[\"GE_saccade_amplitude_095quantiles\"] = amp.quantile(0.95)\n",
    "        res[\"GE_saccade_amplitude_skewness\"] = skew(amp, nan_policy='omit')\n",
    "        res[\"GE_saccade_amplitude_kurtosis\"] = kurtosis(amp, nan_policy='omit')\n",
    "\n",
    "        res[\"GE_saccade_peak_v_mean\"] = pv.mean()\n",
    "        res[\"GE_saccade_peak_v_std\"] = pv.std()\n",
    "        res[\"GE_saccade_peak_v_005quantiles\"] = pv.quantile(0.05)\n",
    "        res[\"GE_saccade_peak_v_095quantiles\"] = pv.quantile(0.95)\n",
    "        res[\"GE_saccade_peak_v_skewness\"] = skew(pv, nan_policy='omit')\n",
    "        res[\"GE_saccade_peak_v_kurtosis\"] = kurtosis(pv, nan_policy='omit')\n",
    "\n",
    "        res[\"GE_saccade_mean_v_mean\"] = mv.mean()\n",
    "        res[\"GE_saccade_mean_v_std\"] = mv.std()\n",
    "        res[\"GE_saccade_mean_v_005quantiles\"] = mv.quantile(0.05)\n",
    "        res[\"GE_saccade_mean_v_095quantiles\"] = mv.quantile(0.95)\n",
    "        res[\"GE_saccade_mean_v_skewness\"] = skew(mv, nan_policy='omit')\n",
    "        res[\"GE_saccade_mean_v_kurtosis\"] = kurtosis(mv, nan_policy='omit')\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# ======================== Eye movement general features =================== #\n",
    "def extract_eye(eye_df):\n",
    "    \"\"\"\n",
    "    Compute eye movement speed statistics.\n",
    "    \"\"\"\n",
    "    res = {\n",
    "        \"LASTE_eye_speed_x_mean\": np.nan,\n",
    "        \"LASTE_eye_speed_y_mean\": np.nan,\n",
    "        \"LASTE_eye_speed_eye_mean\": np.nan,\n",
    "        \"LASTE_eye_speed_x_max\": np.nan,\n",
    "        \"LASTE_eye_speed_y_max\": np.nan,\n",
    "        \"LASTE_eye_speed_eye_max\": np.nan,\n",
    "    }\n",
    "\n",
    "    if eye_df.shape[0] == 0:\n",
    "        return res\n",
    "\n",
    "    x_speed = np.abs(eye_df[\"Gaze point X_derivative\"])\n",
    "    y_speed = np.abs(eye_df[\"Gaze point Y_derivative\"])\n",
    "    all_speed = np.abs(eye_df[\"eyemovement_speed\"])\n",
    "\n",
    "    res[\"LASTE_eye_speed_x_mean\"] = np.nanmean(x_speed) if len(x_speed) > 0 else np.nan\n",
    "    res[\"LASTE_eye_speed_y_mean\"] = np.nanmean(y_speed) if len(y_speed) > 0 else np.nan\n",
    "    res[\"LASTE_eye_speed_eye_mean\"] = np.nanmean(all_speed)\n",
    "\n",
    "    res[\"LASTE_eye_speed_x_max\"] = np.max(x_speed)\n",
    "    res[\"LASTE_eye_speed_y_max\"] = np.max(y_speed)\n",
    "    res[\"LASTE_eye_speed_eye_max\"] = np.max(all_speed)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# ======================== Basic statistical feature calculators =========== #\n",
    "def get_stats(data, key_suffix: str = None, feature_type: str = None):\n",
    "    \"\"\"\n",
    "    Return basic statistics for a signal: mean, std, percentiles, skewness, kurtosis.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'mean': np.nan,\n",
    "        'std': np.nan,\n",
    "        'q5': np.nan,\n",
    "        'q95': np.nan,\n",
    "        'skewness': np.nan,\n",
    "        'kurtosis': np.nan,\n",
    "    }\n",
    "\n",
    "    if len(data) > 0:\n",
    "        results['mean'] = np.mean(data)\n",
    "        results['std'] = np.std(data)\n",
    "        results['q5'] = np.quantile(data, 0.05)\n",
    "        results['q95'] = np.quantile(data, 0.95)\n",
    "        results['skewness'] = skew(data) if np.std(data) >= 1e-8 else np.nan\n",
    "        results['kurtosis'] = kurtosis(data) if np.std(data) >= 1e-8 else np.nan\n",
    "\n",
    "    prefix_map = {\n",
    "        'pedal': 'STATSP_',\n",
    "        'speed': 'STATSS_',\n",
    "        'eyemovement': 'STATSE_',\n",
    "        'head': 'STATSH_'\n",
    "    }\n",
    "\n",
    "    prefix = prefix_map.get(feature_type, '')\n",
    "    if key_suffix is not None:\n",
    "        results = {f\"{prefix}{key_suffix}_{k}\": v for k, v in results.items()}\n",
    "    else:\n",
    "        results = {f\"{prefix}{k}\": v for k, v in results.items()}\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_stats_new(data, key_suffix: str = None, feature_type: str = None):\n",
    "    \"\"\"\n",
    "    Return advanced signal statistics: peak-to-peak, RMS, energy, IQR, etc.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'ptp': np.nan,\n",
    "        'median': np.nan,\n",
    "        'energy': np.nan,\n",
    "        'rms': np.nan,\n",
    "        'lineintegral': np.nan,\n",
    "        'n_sign_changes': np.nan,\n",
    "        'iqr': np.nan,\n",
    "        'iqr_5_95': np.nan\n",
    "    }\n",
    "\n",
    "    if len(data) > 0:\n",
    "        results['ptp'] = np.ptp(data)\n",
    "        results['median'] = np.median(data)\n",
    "        results['energy'] = np.sum(data ** 2)\n",
    "        results['rms'] = np.sqrt(np.sum(data ** 2) / len(data))\n",
    "        results['lineintegral'] = np.abs(np.diff(data)).sum()\n",
    "        results['n_sign_changes'] = np.sum(np.diff(np.sign(data)) != 0)\n",
    "        results['iqr'] = np.subtract(*np.nanpercentile(data, [75, 25]))\n",
    "        results['iqr_5_95'] = np.subtract(*np.nanpercentile(data, [95, 5]))\n",
    "\n",
    "    prefix_map = {\n",
    "        'pedal': 'STATSPNEW_',\n",
    "        'speed': 'STATSSNEW_',\n",
    "        'eyemovement': 'STATSENEW_',\n",
    "        'head': 'STATSHNEW_'\n",
    "    }\n",
    "\n",
    "    prefix = prefix_map.get(feature_type, '')\n",
    "    if key_suffix is not None:\n",
    "        results = {f\"{prefix}{key_suffix}_{k}\": v for k, v in results.items()}\n",
    "    else:\n",
    "        results = {f\"{prefix}{k}\": v for k, v in results.items()}\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding-window feature extraction\n",
    "\n",
    "def get_sliding_window(data: pd.DataFrame, speed_data: pd.DataFrame,\n",
    "                       eyemovement_data: pd.DataFrame, start_end_list):\n",
    "    \"\"\"\n",
    "    Extract aggregated features for a given time window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Pedal-related time-series window subset.\n",
    "    speed_data : pd.DataFrame\n",
    "        Speed-related time-series window subset.\n",
    "    eyemovement_data : pd.DataFrame\n",
    "        Eye-movement-related time-series window subset.\n",
    "    start_end_list : [float, float]\n",
    "        [window_start_timestamp, window_end_timestamp]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary containing all aggregated feature values.\n",
    "    \"\"\"\n",
    "    min_timestamp, max_timestamp = start_end_list\n",
    "\n",
    "    results = {\"datetime\": min_timestamp}\n",
    "\n",
    "    # Select samples inside the time window\n",
    "    relevant_data = data[(data[\"timestamp\"] > min_timestamp) &\n",
    "                         (data[\"timestamp\"] < max_timestamp)]\n",
    "    relevant_speed_data = speed_data[(speed_data[\"timestamp\"] > min_timestamp) &\n",
    "                                     (speed_data[\"timestamp\"] < max_timestamp)]\n",
    "    relevant_eyemovement_data = eyemovement_data[(eyemovement_data[\"timestamp\"] > min_timestamp) &\n",
    "                                                 (eyemovement_data[\"timestamp\"] < max_timestamp)]\n",
    "\n",
    "    # ======================= Pedal features ======================= #\n",
    "    for column in relevant_data.columns:\n",
    "        if column in [\"timestamp\", \"person_id\"]:\n",
    "            continue\n",
    "        stats = get_stats(relevant_data[column], column, \"pedal\")\n",
    "        results.update(stats)\n",
    "        stats_new = get_stats_new(relevant_data[column], column, \"pedal\")\n",
    "        results.update(stats_new)\n",
    "\n",
    "    # Frequency-domain + Wavelet + Handcrafted pedal features\n",
    "    results.update(get_fft_stats(relevant_data))\n",
    "    results.update(extract_wavelet_features(relevant_data))\n",
    "    results.update(extract_pedal(relevant_data))\n",
    "    results.update(extract_new_pedal_feature(relevant_data))\n",
    "\n",
    "    # ======================= Speed features ======================= #\n",
    "    results.update(extract_new_speed_feature(relevant_speed_data))\n",
    "\n",
    "    for column in relevant_speed_data.columns:\n",
    "        if column in [\"timestamp\", \"person_id\"]:\n",
    "            continue\n",
    "        stats = get_stats(relevant_speed_data[column], column, \"speed\")\n",
    "        results.update(stats)\n",
    "        stats_new = get_stats_new(relevant_speed_data[column], column, \"speed\")\n",
    "        results.update(stats_new)\n",
    "\n",
    "    # ======================= Eye movement features ======================= #\n",
    "    for column in relevant_eyemovement_data.columns:\n",
    "        if column in [\n",
    "            \"timestamp\", \"person_id\", \"Eye movement type\",\n",
    "            \"Eye position left X (DACSmm)\", \"Eye position left Y (DACSmm)\",\n",
    "            \"Eye position left Z (DACSmm)\", \"Eye position right X (DACSmm)\",\n",
    "            \"Eye position right Y (DACSmm)\", \"Eye position right Z (DACSmm)\"\n",
    "        ]:\n",
    "            continue\n",
    "\n",
    "        feature_type = \"head\" if column.startswith(\"Head\") else \"eyemovement\"\n",
    "\n",
    "        stats = get_stats(relevant_eyemovement_data[column], column, feature_type)\n",
    "        results.update(stats)\n",
    "        stats_new = get_stats_new(relevant_eyemovement_data[column], column, feature_type)\n",
    "        results.update(stats_new)\n",
    "\n",
    "    # Eye movement segmentation features\n",
    "    results.update(extract_eye_movement_type(relevant_eyemovement_data))\n",
    "    # Optionally: results.update(extract_eye(relevant_eyemovement_data))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_features(data: pd.DataFrame, speed_data: pd.DataFrame,\n",
    "                 eyemovement_data: pd.DataFrame, num_cores: int = 0,\n",
    "                 start_row: int = 0):\n",
    "    \"\"\"\n",
    "    Sliding-window feature extraction over entire dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        Pedal dataset with timestamp.\n",
    "    speed_data : pd.DataFrame\n",
    "        Speed dataset aligned by timestamp.\n",
    "    eyemovement_data : pd.DataFrame\n",
    "        Eye tracking dataset aligned by timestamp.\n",
    "    num_cores : int\n",
    "        Number of CPU cores for future parallel acceleration (unused now).\n",
    "    start_row : int\n",
    "        Not used here but reserved for future functionality.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Feature matrix indexed by window start timestamp.\n",
    "    \"\"\"\n",
    "\n",
    "    input_data = data.copy()\n",
    "    input_speed_data = speed_data.copy()\n",
    "    input_eyemovement_data = eyemovement_data.copy()\n",
    "\n",
    "    total_rows = len(input_data)\n",
    "    windows = []\n",
    "\n",
    "    # ⚠️ These must be already defined from config (unchanged behavior)\n",
    "    global WINDOW_SIZE_S, STEP_SIZE_S\n",
    "    WINDOW_SIZE = WINDOW_SIZE_S\n",
    "    WINDOW_STEP = STEP_SIZE_S\n",
    "\n",
    "    # Build sliding windows\n",
    "    for start in range(0, total_rows - WINDOW_SIZE, WINDOW_STEP):\n",
    "        start_timestamp = float(input_data.iloc[start][\"timestamp\"])\n",
    "        end_timestamp = float(input_data.iloc[start + WINDOW_SIZE][\"timestamp\"])\n",
    "        windows.append([start_timestamp, end_timestamp])\n",
    "\n",
    "    if not windows:\n",
    "        return []\n",
    "\n",
    "    results = [\n",
    "        get_sliding_window(input_data, input_speed_data, input_eyemovement_data, w)\n",
    "        for w in windows\n",
    "    ]\n",
    "\n",
    "    results_df = pd.DataFrame([r for r in results if r is not None])\n",
    "    results_df.set_index(\"datetime\", inplace=True)\n",
    "    results_df.sort_index(inplace=True)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config.config_loader import load_config\n",
    "import os\n",
    "\n",
    "CONFIG_DATA = load_config(os.path.join(\"config\", \"feature_engineering_config.json\"))\n",
    "NC_number = CONFIG_DATA[\"NC_number\"]\n",
    "PD_number = CONFIG_DATA[\"PD_number\"]\n",
    "result = pd.DataFrame()\n",
    "\n",
    "WINDOW_SIZE_LIST = [1275*2]  #120\n",
    "size_list =['120']\n",
    "WINDOW_STEP_LIST = [21]\n",
    "step_list = ['1']\n",
    "output_name= f\"feature_{size_list[0]}_{step_list[0]}.csv\"\n",
    "\n",
    "for type in ['PD','NC']:\n",
    "    for ex in ['ex1','ex2']:\n",
    "\n",
    "        if type == 'PD':\n",
    "            person_amount = PD_number\n",
    "        else:\n",
    "            person_amount = NC_number\n",
    "\n",
    "        for person_num in range(person_amount):\n",
    "            print(\"在处理第\"+str(person_num+1)+\"个文件\")\n",
    "\n",
    "            data_type = \"pedal\"        \n",
    "            pedal_data = pd.read_csv(\n",
    "                                f\"sliced_data/{type}/{type}{person_num + 1}/whole_{data_type}_{ex}.csv\"\n",
    "                            )\n",
    "\n",
    "            data_type = \"speed\"        \n",
    "            speed_data = pd.read_csv(\n",
    "                                f\"sliced_data/{type}/{type}{person_num + 1}/whole_{data_type}_{ex}.csv\"\n",
    "                            )\n",
    "            \n",
    "            data_type = \"eyemovement\"        \n",
    "            eyemovement_data = pd.read_csv(\n",
    "                                f\"sliced_data/{type}/{type}{person_num + 1}/whole_{data_type}_{ex}.csv\"\n",
    "                            )\n",
    "\n",
    "            res = get_features(pedal_data,speed_data,eyemovement_data,0,0)\n",
    "\n",
    "            res = pd.concat([\n",
    "                res,\n",
    "                pd.DataFrame({\n",
    "                    'participant': [f\"{type} P{person_num + 1}\"] * len(res),\n",
    "                    'experiment': [ex] * len(res),\n",
    "                    'label':1 if type =='PD' else 0\n",
    "                }, index=res.index)\n",
    "            ], axis=1)\n",
    "\n",
    "            result = pd.concat([result, res], axis=0)\n",
    "\n",
    "result.to_csv(output_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
